{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-26 14:22:26.849451: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-26 14:22:28.205467: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-26 14:22:28.206218: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-26 14:22:31.597636: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's rmse: 0.655825\n",
      "[2]\tvalid_0's rmse: 0.61167\n",
      "[3]\tvalid_0's rmse: 0.574543\n",
      "[4]\tvalid_0's rmse: 0.542637\n",
      "[5]\tvalid_0's rmse: 0.516908\n",
      "[6]\tvalid_0's rmse: 0.493443\n",
      "[7]\tvalid_0's rmse: 0.470399\n",
      "[8]\tvalid_0's rmse: 0.450852\n",
      "[9]\tvalid_0's rmse: 0.436194\n",
      "[10]\tvalid_0's rmse: 0.423399\n",
      "[11]\tvalid_0's rmse: 0.413296\n",
      "[12]\tvalid_0's rmse: 0.402987\n",
      "[13]\tvalid_0's rmse: 0.393276\n",
      "[14]\tvalid_0's rmse: 0.387414\n",
      "[15]\tvalid_0's rmse: 0.380685\n",
      "[16]\tvalid_0's rmse: 0.375928\n",
      "[17]\tvalid_0's rmse: 0.369497\n",
      "[18]\tvalid_0's rmse: 0.366759\n",
      "[19]\tvalid_0's rmse: 0.360905\n",
      "[20]\tvalid_0's rmse: 0.356972\n",
      "[21]\tvalid_0's rmse: 0.354674\n",
      "[22]\tvalid_0's rmse: 0.350765\n",
      "[23]\tvalid_0's rmse: 0.348549\n",
      "[24]\tvalid_0's rmse: 0.346686\n",
      "[25]\tvalid_0's rmse: 0.343834\n",
      "[26]\tvalid_0's rmse: 0.341542\n",
      "[27]\tvalid_0's rmse: 0.338967\n",
      "[28]\tvalid_0's rmse: 0.337124\n",
      "[29]\tvalid_0's rmse: 0.33497\n",
      "[30]\tvalid_0's rmse: 0.334863\n",
      "[31]\tvalid_0's rmse: 0.333186\n",
      "[32]\tvalid_0's rmse: 0.332544\n",
      "[33]\tvalid_0's rmse: 0.329333\n",
      "[34]\tvalid_0's rmse: 0.328808\n",
      "[35]\tvalid_0's rmse: 0.326188\n",
      "[36]\tvalid_0's rmse: 0.325464\n",
      "[37]\tvalid_0's rmse: 0.32399\n",
      "[38]\tvalid_0's rmse: 0.324163\n",
      "[39]\tvalid_0's rmse: 0.32305\n",
      "[40]\tvalid_0's rmse: 0.322577\n",
      "[41]\tvalid_0's rmse: 0.320839\n",
      "[42]\tvalid_0's rmse: 0.319874\n",
      "[43]\tvalid_0's rmse: 0.319257\n",
      "[44]\tvalid_0's rmse: 0.318227\n",
      "[45]\tvalid_0's rmse: 0.317837\n",
      "[46]\tvalid_0's rmse: 0.316795\n",
      "[47]\tvalid_0's rmse: 0.315498\n",
      "[48]\tvalid_0's rmse: 0.314932\n",
      "[49]\tvalid_0's rmse: 0.314991\n",
      "[50]\tvalid_0's rmse: 0.314994\n",
      "[51]\tvalid_0's rmse: 0.314586\n",
      "[52]\tvalid_0's rmse: 0.315374\n",
      "[53]\tvalid_0's rmse: 0.314867\n",
      "[54]\tvalid_0's rmse: 0.315298\n",
      "[55]\tvalid_0's rmse: 0.315197\n",
      "[56]\tvalid_0's rmse: 0.315015\n",
      "[57]\tvalid_0's rmse: 0.315149\n",
      "[58]\tvalid_0's rmse: 0.314795\n",
      "[59]\tvalid_0's rmse: 0.314187\n",
      "[60]\tvalid_0's rmse: 0.31418\n",
      "[61]\tvalid_0's rmse: 0.315229\n",
      "[62]\tvalid_0's rmse: 0.315113\n",
      "[63]\tvalid_0's rmse: 0.314412\n",
      "[64]\tvalid_0's rmse: 0.314933\n",
      "[65]\tvalid_0's rmse: 0.314803\n",
      "[66]\tvalid_0's rmse: 0.31557\n",
      "[67]\tvalid_0's rmse: 0.315283\n",
      "[68]\tvalid_0's rmse: 0.314905\n",
      "[69]\tvalid_0's rmse: 0.314907\n",
      "[70]\tvalid_0's rmse: 0.314977\n",
      "[71]\tvalid_0's rmse: 0.314961\n",
      "[72]\tvalid_0's rmse: 0.315081\n",
      "[73]\tvalid_0's rmse: 0.315097\n",
      "[74]\tvalid_0's rmse: 0.315741\n",
      "[75]\tvalid_0's rmse: 0.315277\n",
      "[76]\tvalid_0's rmse: 0.315856\n",
      "[77]\tvalid_0's rmse: 0.315752\n",
      "[78]\tvalid_0's rmse: 0.315398\n",
      "[79]\tvalid_0's rmse: 0.315349\n",
      "[80]\tvalid_0's rmse: 0.314597\n",
      "[81]\tvalid_0's rmse: 0.314868\n",
      "[82]\tvalid_0's rmse: 0.314516\n",
      "[83]\tvalid_0's rmse: 0.314493\n",
      "[84]\tvalid_0's rmse: 0.314297\n",
      "[85]\tvalid_0's rmse: 0.3143\n",
      "[86]\tvalid_0's rmse: 0.314316\n",
      "[87]\tvalid_0's rmse: 0.313948\n",
      "[88]\tvalid_0's rmse: 0.31349\n",
      "[89]\tvalid_0's rmse: 0.313317\n",
      "[90]\tvalid_0's rmse: 0.313443\n",
      "[91]\tvalid_0's rmse: 0.313103\n",
      "[92]\tvalid_0's rmse: 0.312901\n",
      "[93]\tvalid_0's rmse: 0.312949\n",
      "[94]\tvalid_0's rmse: 0.312682\n",
      "[95]\tvalid_0's rmse: 0.312103\n",
      "[96]\tvalid_0's rmse: 0.311907\n",
      "[97]\tvalid_0's rmse: 0.311524\n",
      "[98]\tvalid_0's rmse: 0.311273\n",
      "[99]\tvalid_0's rmse: 0.311293\n",
      "[100]\tvalid_0's rmse: 0.311362\n",
      "[1]\tvalid_0's rmse: 1.72422\n",
      "[2]\tvalid_0's rmse: 1.6033\n",
      "[3]\tvalid_0's rmse: 1.48773\n",
      "[4]\tvalid_0's rmse: 1.38967\n",
      "[5]\tvalid_0's rmse: 1.3022\n",
      "[6]\tvalid_0's rmse: 1.2297\n",
      "[7]\tvalid_0's rmse: 1.16108\n",
      "[8]\tvalid_0's rmse: 1.09806\n",
      "[9]\tvalid_0's rmse: 1.04266\n",
      "[10]\tvalid_0's rmse: 0.993256\n",
      "[11]\tvalid_0's rmse: 0.949528\n",
      "[12]\tvalid_0's rmse: 0.910273\n",
      "[13]\tvalid_0's rmse: 0.874188\n",
      "[14]\tvalid_0's rmse: 0.844365\n",
      "[15]\tvalid_0's rmse: 0.818311\n",
      "[16]\tvalid_0's rmse: 0.795562\n",
      "[17]\tvalid_0's rmse: 0.774372\n",
      "[18]\tvalid_0's rmse: 0.754813\n",
      "[19]\tvalid_0's rmse: 0.739264\n",
      "[20]\tvalid_0's rmse: 0.723284\n",
      "[21]\tvalid_0's rmse: 0.709333\n",
      "[22]\tvalid_0's rmse: 0.698506\n",
      "[23]\tvalid_0's rmse: 0.686408\n",
      "[24]\tvalid_0's rmse: 0.674976\n",
      "[25]\tvalid_0's rmse: 0.666951\n",
      "[26]\tvalid_0's rmse: 0.659474\n",
      "[27]\tvalid_0's rmse: 0.650754\n",
      "[28]\tvalid_0's rmse: 0.642837\n",
      "[29]\tvalid_0's rmse: 0.638508\n",
      "[30]\tvalid_0's rmse: 0.633187\n",
      "[31]\tvalid_0's rmse: 0.63012\n",
      "[32]\tvalid_0's rmse: 0.627575\n",
      "[33]\tvalid_0's rmse: 0.622994\n",
      "[34]\tvalid_0's rmse: 0.618535\n",
      "[35]\tvalid_0's rmse: 0.613671\n",
      "[36]\tvalid_0's rmse: 0.610243\n",
      "[37]\tvalid_0's rmse: 0.606975\n",
      "[38]\tvalid_0's rmse: 0.604109\n",
      "[39]\tvalid_0's rmse: 0.601182\n",
      "[40]\tvalid_0's rmse: 0.599772\n",
      "[41]\tvalid_0's rmse: 0.597832\n",
      "[42]\tvalid_0's rmse: 0.596522\n",
      "[43]\tvalid_0's rmse: 0.593387\n",
      "[44]\tvalid_0's rmse: 0.592581\n",
      "[45]\tvalid_0's rmse: 0.592614\n",
      "[46]\tvalid_0's rmse: 0.589774\n",
      "[47]\tvalid_0's rmse: 0.587657\n",
      "[48]\tvalid_0's rmse: 0.586411\n",
      "[49]\tvalid_0's rmse: 0.586798\n",
      "[50]\tvalid_0's rmse: 0.585515\n",
      "[51]\tvalid_0's rmse: 0.583734\n",
      "[52]\tvalid_0's rmse: 0.583884\n",
      "[53]\tvalid_0's rmse: 0.583046\n",
      "[54]\tvalid_0's rmse: 0.582206\n",
      "[55]\tvalid_0's rmse: 0.582105\n",
      "[56]\tvalid_0's rmse: 0.580236\n",
      "[57]\tvalid_0's rmse: 0.578864\n",
      "[58]\tvalid_0's rmse: 0.578755\n",
      "[59]\tvalid_0's rmse: 0.577624\n",
      "[60]\tvalid_0's rmse: 0.57664\n",
      "[61]\tvalid_0's rmse: 0.576357\n",
      "[62]\tvalid_0's rmse: 0.575262\n",
      "[63]\tvalid_0's rmse: 0.57496\n",
      "[64]\tvalid_0's rmse: 0.574386\n",
      "[65]\tvalid_0's rmse: 0.572121\n",
      "[66]\tvalid_0's rmse: 0.57114\n",
      "[67]\tvalid_0's rmse: 0.570182\n",
      "[68]\tvalid_0's rmse: 0.569677\n",
      "[69]\tvalid_0's rmse: 0.567877\n",
      "[70]\tvalid_0's rmse: 0.56833\n",
      "[71]\tvalid_0's rmse: 0.567278\n",
      "[72]\tvalid_0's rmse: 0.566163\n",
      "[73]\tvalid_0's rmse: 0.56538\n",
      "[74]\tvalid_0's rmse: 0.56606\n",
      "[75]\tvalid_0's rmse: 0.565431\n",
      "[76]\tvalid_0's rmse: 0.564002\n",
      "[77]\tvalid_0's rmse: 0.56331\n",
      "[78]\tvalid_0's rmse: 0.563898\n",
      "[79]\tvalid_0's rmse: 0.563233\n",
      "[80]\tvalid_0's rmse: 0.562057\n",
      "[81]\tvalid_0's rmse: 0.562081\n",
      "[82]\tvalid_0's rmse: 0.56066\n",
      "[83]\tvalid_0's rmse: 0.559561\n",
      "[84]\tvalid_0's rmse: 0.559041\n",
      "[85]\tvalid_0's rmse: 0.558377\n",
      "[86]\tvalid_0's rmse: 0.558452\n",
      "[87]\tvalid_0's rmse: 0.558346\n",
      "[88]\tvalid_0's rmse: 0.557909\n",
      "[89]\tvalid_0's rmse: 0.557128\n",
      "[90]\tvalid_0's rmse: 0.557233\n",
      "[91]\tvalid_0's rmse: 0.558118\n",
      "[92]\tvalid_0's rmse: 0.556993\n",
      "[93]\tvalid_0's rmse: 0.556528\n",
      "[94]\tvalid_0's rmse: 0.556413\n",
      "[95]\tvalid_0's rmse: 0.556987\n",
      "[96]\tvalid_0's rmse: 0.556349\n",
      "[97]\tvalid_0's rmse: 0.555383\n",
      "[98]\tvalid_0's rmse: 0.554933\n",
      "[99]\tvalid_0's rmse: 0.555128\n",
      "[100]\tvalid_0's rmse: 0.554987\n",
      "RMSE for oss model: 0.5570907745458885\n",
      "RMSE for sleepiness model: 1.3892397677663821\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "def read_and_process(file):\n",
    "  df = pd.read_csv(file)\n",
    "  df = df.drop(['timestamp'], axis=1)\n",
    "  df = df.dropna()  # 無効値を含む行を削除\n",
    "  return df\n",
    "\n",
    "def train_model(X, y):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "  train_data = lgb.Dataset(X_train, label=y_train)\n",
    "  eval_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "  params = {\n",
    "      'objective': 'regression',\n",
    "      'metric': 'rmse',\n",
    "      'verbose':-1\n",
    "  }\n",
    "  model = lgb.train(params, train_data, valid_sets=eval_data)\n",
    "  return model, X_test, y_test\n",
    "\n",
    "\n",
    "# 訓練データを処理\n",
    "train_data_path = './train'\n",
    "train_data_path = './dms_data/train'\n",
    "files = os.listdir(train_data_path)\n",
    "\n",
    "df_list = []\n",
    "for file in files:\n",
    "  if file.endswith('.csv'):\n",
    "    df = read_and_process(os.path.join(train_data_path, file))\n",
    "    df_list.append(df)\n",
    "\n",
    "# データを結合\n",
    "train_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 特徴量と目的変数に分割 (oss)\n",
    "X_oss = train_df.drop(['oss', 'Sleepiness'], axis=1)\n",
    "y_oss = train_df['oss']\n",
    "\n",
    "# 特徴量と目的変数に分割 (Sleepiness)\n",
    "X_sleepiness = train_df.drop(['oss', 'Sleepiness'], axis=1)\n",
    "y_sleepiness = train_df['Sleepiness']\n",
    "\n",
    "# モデルの学習 (oss)\n",
    "model_oss, X_test_oss, y_test_oss = train_model(X_oss, y_oss)\n",
    "\n",
    "# モデルの学習 (Sleepiness)\n",
    "model_sleepiness, X_test_sleepiness, y_test_sleepiness = train_model(X_sleepiness, y_sleepiness)\n",
    "\n",
    "# テストデータを処理\n",
    "test_data_path = './test'\n",
    "test_data_path = './dms_data/test'\n",
    "files = os.listdir(test_data_path)\n",
    "\n",
    "df_list = []\n",
    "for file in files:\n",
    "  if file.endswith('.csv'):\n",
    "    df = read_and_process(os.path.join(test_data_path, file))\n",
    "    df_list.append(df)\n",
    "\n",
    "# データを結合\n",
    "test_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 特徴量と目的変数に分割 (oss)\n",
    "X_test_oss = test_df.drop(['oss', 'Sleepiness'], axis=1)\n",
    "y_test_oss = test_df['oss']\n",
    "\n",
    "# 特徴量と目的変数に分割 (Sleepiness)\n",
    "X_test_sleepiness = test_df.drop(['oss', 'Sleepiness'], axis=1)\n",
    "y_test_sleepiness = test_df['Sleepiness']\n",
    "\n",
    "# モデルの評価 (oss)\n",
    "oss_preds = model_oss.predict(X_test_oss)\n",
    "oss_rmse = np.sqrt(mean_squared_error(y_test_oss, oss_preds))\n",
    "print(f\"RMSE for oss model: {oss_rmse}\")\n",
    "\n",
    "# モデルの評価 (Sleepiness)\n",
    "sleepiness_preds = model_sleepiness.predict(X_test_sleepiness)\n",
    "sleepiness_rmse = np.sqrt(mean_squared_error(y_test_sleepiness, sleepiness_preds))\n",
    "print(f\"RMSE for sleepiness model: {sleepiness_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Linear Regression (oss) model: 0.5743600270704748\n",
      "RMSE for Linear Regression (Sleepiness) model: 1.5044710625022029\n",
      "17/17 [==============================] - 0s 574us/step\n",
      "RMSE for Neural Network (oss) model: 0.725327057005296\n",
      "17/17 [==============================] - 0s 666us/step\n",
      "RMSE for Neural Network (Sleepiness) model: 1.7297672201774685\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 線形回帰モデルの学習 (oss)\n",
    "lin_reg_oss = LinearRegression().fit(X_oss, y_oss)\n",
    "lin_reg_oss_preds = lin_reg_oss.predict(X_test_oss)\n",
    "lin_reg_oss_rmse = np.sqrt(mean_squared_error(y_test_oss, lin_reg_oss_preds))\n",
    "print(f\"RMSE for Linear Regression (oss) model: {lin_reg_oss_rmse}\")\n",
    "\n",
    "# 線形回帰モデルの学習 (Sleepiness)\n",
    "lin_reg_sleepiness = LinearRegression().fit(X_sleepiness, y_sleepiness)\n",
    "lin_reg_sleepiness_preds = lin_reg_sleepiness.predict(X_test_sleepiness)\n",
    "lin_reg_sleepiness_rmse = np.sqrt(mean_squared_error(y_test_sleepiness, lin_reg_sleepiness_preds))\n",
    "print(f\"RMSE for Linear Regression (Sleepiness) model: {lin_reg_sleepiness_rmse}\")\n",
    "\n",
    "# ニューラルネットワークモデルの構造定義\n",
    "\n",
    "\n",
    "def create_nn_model(input_shape):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(32, activation='relu', input_shape=(input_shape,)))\n",
    "  model.add(Dense(32, activation='relu'))\n",
    "  model.add(Dense(1))\n",
    "  model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "  return model\n",
    "\n",
    "\n",
    "# ニューラルネットワークモデルの学習 (oss)\n",
    "nn_model_oss = create_nn_model(X_oss.shape[1])\n",
    "nn_model_oss.fit(X_oss, y_oss, epochs=10, verbose=0)\n",
    "nn_oss_preds = nn_model_oss.predict(X_test_oss).flatten()\n",
    "nn_oss_rmse = np.sqrt(mean_squared_error(y_test_oss, nn_oss_preds))\n",
    "print(f\"RMSE for Neural Network (oss) model: {nn_oss_rmse}\")\n",
    "\n",
    "# ニューラルネットワークモデルの学習 (Sleepiness)\n",
    "nn_model_sleepiness = create_nn_model(X_sleepiness.shape[1])\n",
    "nn_model_sleepiness.fit(X_sleepiness, y_sleepiness, epochs=10, verbose=0)\n",
    "nn_sleepiness_preds = nn_model_sleepiness.predict(X_test_sleepiness).flatten()\n",
    "nn_sleepiness_rmse = np.sqrt(mean_squared_error(y_test_sleepiness, nn_sleepiness_preds))\n",
    "print(f\"RMSE for Neural Network (Sleepiness) model: {nn_sleepiness_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_csv('./dms_data/train/20201126_1546_0_y_train.csv').drop(columns=['timestamp']).dropna();\n",
    "test = pd.read_csv('./dms_data/test/20201126_1546_0_y_test.csv').drop(columns=['timestamp']).dropna();\n",
    "\n",
    "# 特徴量のリスト\n",
    "features = ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration',\n",
    "            'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk',\n",
    "            'm_jerk_var_480', 'm_jerk_stddev_480']\n",
    "\n",
    "# 特徴量の全ての組み合わせを生成\n",
    "feature_combinations = []\n",
    "for r in range(1, len(features) + 1):\n",
    "  for subset in itertools.combinations(features, r):\n",
    "    feature_combinations.append(list(subset))\n",
    "\n",
    "# RMSEと特徴量の組み合わせを記録するテキストファイルを開く\n",
    "with open(\"feature_selection_results.txt\", \"w\") as f:\n",
    "  # 各特徴量の組み合わせについて\n",
    "  for feature_comb in feature_combinations:\n",
    "    # モデルの訓練\n",
    "    lgb_data = lgb.Dataset(train[feature_comb], label=train['oss'])\n",
    "    lgb_model = lgb.train({'verbose':-1}, lgb_data)\n",
    "    # テストデータでの予測\n",
    "    preds = lgb_model.predict(test[feature_comb])\n",
    "    # RMSEの計算\n",
    "    rmse = np.sqrt(mean_squared_error(test['oss'], preds))\n",
    "    # テキストファイルに結果を出力\n",
    "    f.write(f\"Features: {feature_comb}, RMSE: {rmse}\\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1正規化と総当たりの比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature combination: ['m_speed_var_480', 'm_acceleration', 'm_jerk', 'm_jerk_var_480']\n",
      "Selected features by Lasso: ['m_speed' 'm_speed_var_480' 'm_speed_stddev_480']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# 特徴量の全ての組み合わせについてのRMSEを格納するリスト\n",
    "rmses = []\n",
    "\n",
    "# 各特徴量の組み合わせについて\n",
    "for feature_comb in feature_combinations:\n",
    "  # モデルの訓練\n",
    "  lgb_data = lgb.Dataset(train[feature_comb], label=train['oss'])\n",
    "  lgb_model = lgb.train({'verbose':-1}, lgb_data)\n",
    "\n",
    "  # テストデータでの予測\n",
    "  preds = lgb_model.predict(test[feature_comb])\n",
    "\n",
    "  # RMSEの計算\n",
    "  rmse = np.sqrt(mean_squared_error(test['oss'], preds))\n",
    "  rmses.append(rmse)\n",
    "\n",
    "# 最も小さいRMSEを持つ組み合わせを取得\n",
    "best_comb = feature_combinations[np.argmin(rmses)]\n",
    "print(f\"Best feature combination: {best_comb}\")\n",
    "\n",
    "# Lassoによる特徴量選択\n",
    "lasso = LassoCV(cv=5).fit(train[features], train['oss'])\n",
    "\n",
    "# 非ゼロの係数を持つ特徴量を取得\n",
    "selected_features = np.array(features)[lasso.coef_ != 0]\n",
    "print(f\"Selected features by Lasso: {selected_features}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### oss,sleepinessの正規化忘れてた。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 40\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39m# データの読み込み\u001b[39;00m\n\u001b[1;32m     39\u001b[0m train_data_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./train\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 40\u001b[0m df_train \u001b[39m=\u001b[39m load_data(train_data_path)\n\u001b[1;32m     42\u001b[0m \u001b[39m# データの前処理と分割\u001b[39;00m\n\u001b[1;32m     43\u001b[0m X_oss_train, y_oss_train, X_sleepiness_train, y_sleepiness_train \u001b[39m=\u001b[39m preprocess_and_split(df_train)\n",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_data\u001b[39m(data_path):\n\u001b[0;32m----> 5\u001b[0m   files \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(data_path)\n\u001b[1;32m      6\u001b[0m   df_list \u001b[39m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m   \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "def read_and_process(file):\n",
    "  df = pd.read_csv(file)\n",
    "  df = df.drop(['timestamp'], axis=1)\n",
    "  df = df.dropna()  # 無効値を含む行を削除\n",
    "  return df\n",
    "\n",
    "def train_model(X, y):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "  train_data = lgb.Dataset(X_train, label=y_train)\n",
    "  eval_data = lgb.Dataset(X_test, label=y_test, reference=train_data)\n",
    "  params = {\n",
    "      'objective': 'regression',\n",
    "      'metric': 'rmse',\n",
    "      'verbose':-1\n",
    "  }\n",
    "  model = lgb.train(params, train_data, valid_sets=eval_data)\n",
    "  return model, X_test, y_test\n",
    "\n",
    "\n",
    "# 訓練データを処理\n",
    "train_data_path = './train'\n",
    "train_data_path = './dms_data/train'\n",
    "files = os.listdir(train_data_path)\n",
    "\n",
    "df_list = []\n",
    "for file in files:\n",
    "  if file.endswith('.csv'):\n",
    "    df = read_and_process(os.path.join(train_data_path, file))\n",
    "    df_list.append(df)\n",
    "\n",
    "# データを結合\n",
    "train_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 特徴量と目的変数に分割 (oss)\n",
    "X_oss = train_df.drop(['oss', 'Sleepiness'], axis=1)\n",
    "y_oss = train_df['oss']\n",
    "\n",
    "# 特徴量と目的変数に分割 (Sleepiness)\n",
    "X_sleepiness = train_df.drop(['oss', 'Sleepiness'], axis=1)\n",
    "y_sleepiness = train_df['Sleepiness']\n",
    "\n",
    "# モデルの学習 (oss)\n",
    "model_oss, X_test_oss, y_test_oss = train_model(X_oss, y_oss)\n",
    "\n",
    "# モデルの学習 (Sleepiness)\n",
    "model_sleepiness, X_test_sleepiness, y_test_sleepiness = train_model(X_sleepiness, y_sleepiness)\n",
    "\n",
    "# テストデータを処理\n",
    "test_data_path = './test'\n",
    "test_data_path = './dms_data/test'\n",
    "files = os.listdir(test_data_path)\n",
    "\n",
    "df_list = []\n",
    "for file in files:\n",
    "  if file.endswith('.csv'):\n",
    "    df = read_and_process(os.path.join(test_data_path, file))\n",
    "    df_list.append(df)\n",
    "\n",
    "# データを結合\n",
    "test_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# 特徴量と目的変数に分割 (oss)\n",
    "X_test_oss = test_df.drop(['oss', 'Sleepiness'], axis=1)\n",
    "y_test_oss = test_df['oss']\n",
    "\n",
    "# 特徴量と目的変数に分割 (Sleepiness)\n",
    "X_test_sleepiness = test_df.drop(['oss', 'Sleepiness'], axis=1)\n",
    "y_test_sleepiness = test_df['Sleepiness']\n",
    "\n",
    "# モデルの評価 (oss)\n",
    "oss_preds = model_oss.predict(X_test_oss)\n",
    "oss_rmse = np.sqrt(mean_squared_error(y_test_oss, oss_preds))\n",
    "print(f\"RMSE for oss model: {oss_rmse}\")\n",
    "\n",
    "# モデルの評価 (Sleepiness)\n",
    "sleepiness_preds = model_sleepiness.predict(X_test_sleepiness)\n",
    "sleepiness_rmse = np.sqrt(mean_squared_error(y_test_sleepiness, sleepiness_preds))\n",
    "print(f\"RMSE for sleepiness model: {sleepiness_rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
