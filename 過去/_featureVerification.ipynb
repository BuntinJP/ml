{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "496c9019-2803-4527-8c75-0c38e7517b75",
   "metadata": {},
   "source": [
    "#### 特徴量について検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d260c8c9-7fa1-4890-b675-f1a6a4ec7e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'dms_data'\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a202bf2-e326-44b4-b557-1cb63685c4bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_and_evaluate(model_type, X_train, y_train, X_test, y_test):\n",
    "    if model_type == \"lgbm\":\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        model = lgb.train({'verbose':-1}, train_data)\n",
    "    elif model_type == \"nn\":\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(1))\n",
    "        model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "        model.fit(X_train, y_train, epochs=10, verbose=0)\n",
    "    elif model_type == \"linear_regression\":\n",
    "        model = LinearRegression().fit(X_train, y_train)\n",
    "    elif model_type == \"svr\":\n",
    "        model = SVR().fit(X_train, y_train)\n",
    "    elif model_type == \"random_forest\":\n",
    "        model = RandomForestRegressor().fit(X_train, y_train)\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    \n",
    "    return model, rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52ac3163-43c5-4585-abd9-baafacea0105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_best_combination(model_type, combinations, train, test):\n",
    "    rmses = []\n",
    "    for feature_comb in combinations:\n",
    "        _, rmse = train_and_evaluate(model_type, train[feature_comb], train['oss'], test[feature_comb], test['oss'])\n",
    "        rmses.append(rmse)\n",
    "\n",
    "    best_comb = combinations[np.argmin(rmses)]\n",
    "    print(rmses)\n",
    "    return best_comb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ffbb1487-ddba-443c-b166-5c63dec46efe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_and_process(directory):\n",
    "  files = os.listdir(directory)\n",
    "  df_list = []\n",
    "  for file in files:\n",
    "    if file.endswith('.csv'):\n",
    "      df = pd.read_csv(os.path.join(directory, file))\n",
    "      df = df.drop(['timestamp'], axis=1)\n",
    "      df = df.dropna()\n",
    "      df_list.append(df)\n",
    "  df_combined = pd.concat(df_list, ignore_index=True)\n",
    "  \n",
    "  return df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "287e2737-2cef-4f8b-9a59-e50ef28a196e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: lgbm\n",
      "[0.7448632962609215]\n",
      "Best feature combination for lgbm: ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration', 'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk', 'm_jerk_var_480', 'm_jerk_stddev_480']\n",
      "model: nn\n",
      "17/17 [==============================] - 0s 562us/step\n",
      "[0.7911743571740701]\n",
      "Best feature combination for nn: ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration', 'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk', 'm_jerk_var_480', 'm_jerk_stddev_480']\n",
      "model: linear_regression\n",
      "[0.6548148950163442]\n",
      "Best feature combination for linear_regression: ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration', 'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk', 'm_jerk_var_480', 'm_jerk_stddev_480']\n",
      "model: svr\n",
      "[0.694881610724204]\n",
      "Best feature combination for svr: ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration', 'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk', 'm_jerk_var_480', 'm_jerk_stddev_480']\n",
      "model: random_forest\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7114483681803272]\n",
      "Best feature combination for random_forest: ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration', 'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk', 'm_jerk_var_480', 'm_jerk_stddev_480']\n"
     ]
    }
   ],
   "source": [
    "def show_result():\n",
    "    # Define directory paths\n",
    "  train_data_path = data_dir + '/train'\n",
    "  test_data_path = data_dir + '/test'\n",
    "\n",
    "  # Read and process data\n",
    "  train = read_and_process(train_data_path)\n",
    "  test = read_and_process(test_data_path)\n",
    "\n",
    "  # Define features\n",
    "  features = ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration',\n",
    "              'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk',\n",
    "              'm_jerk_var_480', 'm_jerk_stddev_480']\n",
    "\n",
    "  # Generate all combinations of features\n",
    "  feature_combinations = []\n",
    "  for r in range(1, len(features) + 1):\n",
    "    for subset in itertools.combinations(features, r):\n",
    "      feature_combinations.append(list(subset))\n",
    "\n",
    "  # Define models\n",
    "  models = [\"lgbm\", \"nn\", \"linear_regression\", \"svr\", \"random_forest\"]\n",
    "\n",
    "  # Find the best combination for each model\n",
    "  for model in models:\n",
    "    print('model: ' + model)\n",
    "    best_comb = find_best_combination(model, [features], train, test)\n",
    "    print(f\"Best feature combination for {model}: {best_comb}\")\n",
    "\n",
    "show_result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d1d9f54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: lgbm\n",
      "[0.7448632962609215]\n",
      "Best feature combination for lgbm: ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration', 'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk', 'm_jerk_var_480', 'm_jerk_stddev_480']\n",
      "model: nn\n",
      "17/17 [==============================] - 0s 582us/step\n",
      "[0.6670130662064958]\n",
      "Best feature combination for nn: ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration', 'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk', 'm_jerk_var_480', 'm_jerk_stddev_480']\n",
      "model: linear_regression\n",
      "[0.6548148950163442]\n",
      "Best feature combination for linear_regression: ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration', 'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk', 'm_jerk_var_480', 'm_jerk_stddev_480']\n",
      "model: svr\n",
      "[0.694881610724204]\n",
      "Best feature combination for svr: ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration', 'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk', 'm_jerk_var_480', 'm_jerk_stddev_480']\n",
      "model: random_forest\n",
      "[0.7137847368347847]\n",
      "Best feature combination for random_forest: ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration', 'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk', 'm_jerk_var_480', 'm_jerk_stddev_480']\n"
     ]
    }
   ],
   "source": [
    "def show_result():\n",
    "    # Define directory paths\n",
    "  train_data_path = data_dir + '/train'\n",
    "  test_data_path = data_dir + '/test'\n",
    "\n",
    "  # Read and process data\n",
    "  train = read_and_process(train_data_path)\n",
    "  test = read_and_process(test_data_path)\n",
    "\n",
    "  # Define features\n",
    "  features = ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration',\n",
    "              'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk',\n",
    "              'm_jerk_var_480', 'm_jerk_stddev_480']\n",
    "\n",
    "  # Generate all combinations of features\n",
    "  feature_combinations = []\n",
    "  for r in range(1, len(features) + 1):\n",
    "    for subset in itertools.combinations(features, r):\n",
    "      feature_combinations.append(list(subset))\n",
    "\n",
    "  # Define models\n",
    "  models = [\"lgbm\", \"nn\", \"linear_regression\", \"svr\", \"random_forest\"]\n",
    "\n",
    "  # Find the best combination for each model\n",
    "  for model in models:\n",
    "    print('model: ' + model)\n",
    "    best_comb = find_best_combination(model, [features], train, test)\n",
    "    print(f\"Best feature combination for {model}: {best_comb}\")\n",
    "\n",
    "\n",
    "show_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1d983b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'dms_data'\n",
    "# Define directory paths\n",
    "train_data_path = data_dir + '/train'\n",
    "test_data_path = data_dir + '/test'\n",
    "\n",
    "# Read and process data\n",
    "train = read_and_process(train_data_path)\n",
    "test = read_and_process(test_data_path)\n",
    "features = ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration',\n",
    "            'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk',\n",
    "            'm_jerk_var_480', 'm_jerk_stddev_480']\n",
    "X_train, y_train, X_test, y_test = train[features], train['oss'], test[features], test['oss']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d05eb19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model: lgbm\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/buntin/gits/ml/_featureVerification.ipynb セル 9\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m       \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest feature combination for \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mbest_comb\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m       \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest RMSE for \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mbest_rmse\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=77'>78</a>\u001b[0m with_RMSE()\n",
      "\u001b[1;32m/home/buntin/gits/ml/_featureVerification.ipynb セル 9\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m models:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=73'>74</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmodel: \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m model)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=74'>75</a>\u001b[0m     best_comb, best_rmse \u001b[39m=\u001b[39m find_best_combination(model, feature_combinations, train, test)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=75'>76</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest feature combination for \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mbest_comb\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=76'>77</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest RMSE for \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mbest_rmse\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/home/buntin/gits/ml/_featureVerification.ipynb セル 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m rmses \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m feature_comb \u001b[39min\u001b[39;00m combinations:\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m     _, rmse \u001b[39m=\u001b[39m train_and_evaluate(model_type, train[feature_comb], train[\u001b[39m'\u001b[39;49m\u001b[39moss\u001b[39;49m\u001b[39m'\u001b[39;49m], test[feature_comb], test[\u001b[39m'\u001b[39;49m\u001b[39moss\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m     rmses\u001b[39m.\u001b[39mappend(rmse)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=29'>30</a>\u001b[0m min_rmse_index \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmin(rmses)\n",
      "\u001b[1;32m/home/buntin/gits/ml/_featureVerification.ipynb セル 9\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mif\u001b[39;00m model_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlgbm\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m     train_data \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39mDataset(X_train, label\u001b[39m=\u001b[39my_train)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     model \u001b[39m=\u001b[39m lgb\u001b[39m.\u001b[39;49mtrain({\u001b[39m'\u001b[39;49m\u001b[39mverbose\u001b[39;49m\u001b[39m'\u001b[39;49m:\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m}, train_data)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39melif\u001b[39;00m model_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnn\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Brhel2/home/buntin/gits/ml/_featureVerification.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     model \u001b[39m=\u001b[39m Sequential()\n",
      "File \u001b[0;32m~/jupyter-env/lib64/python3.9/site-packages/lightgbm/engine.py:292\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mfor\u001b[39;00m cb \u001b[39min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    285\u001b[0m     cb(callback\u001b[39m.\u001b[39mCallbackEnv(model\u001b[39m=\u001b[39mbooster,\n\u001b[1;32m    286\u001b[0m                             params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    287\u001b[0m                             iteration\u001b[39m=\u001b[39mi,\n\u001b[1;32m    288\u001b[0m                             begin_iteration\u001b[39m=\u001b[39minit_iteration,\n\u001b[1;32m    289\u001b[0m                             end_iteration\u001b[39m=\u001b[39minit_iteration \u001b[39m+\u001b[39m num_boost_round,\n\u001b[1;32m    290\u001b[0m                             evaluation_result_list\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m))\n\u001b[0;32m--> 292\u001b[0m booster\u001b[39m.\u001b[39;49mupdate(fobj\u001b[39m=\u001b[39;49mfobj)\n\u001b[1;32m    294\u001b[0m evaluation_result_list \u001b[39m=\u001b[39m []\n\u001b[1;32m    295\u001b[0m \u001b[39m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m~/jupyter-env/lib64/python3.9/site-packages/lightgbm/basic.py:3021\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3019\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3020\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(\u001b[39m'\u001b[39m\u001b[39mCannot update due to null objective function.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 3021\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3022\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[1;32m   3023\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(is_finished)))\n\u001b[1;32m   3024\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__is_predicted_cur_iter \u001b[39m=\u001b[39m [\u001b[39mFalse\u001b[39;00m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3025\u001b[0m \u001b[39mreturn\u001b[39;00m is_finished\u001b[39m.\u001b[39mvalue \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(model_type, X_train, y_train, X_test, y_test):\n",
    "  if model_type == \"lgbm\":\n",
    "      train_data = lgb.Dataset(X_train, label=y_train)\n",
    "      model = lgb.train({'verbose':-1}, train_data)\n",
    "  elif model_type == \"nn\":\n",
    "      model = Sequential()\n",
    "      model.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "      model.add(Dense(32, activation='relu'))\n",
    "      model.add(Dense(1))\n",
    "      model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "      model.fit(X_train, y_train, epochs=10, verbose=0)\n",
    "  elif model_type == \"linear_regression\":\n",
    "      model = LinearRegression().fit(X_train, y_train)\n",
    "  elif model_type == \"svr\":\n",
    "      model = SVR().fit(X_train, y_train)\n",
    "  elif model_type == \"random_forest\":\n",
    "      model = RandomForestRegressor().fit(X_train, y_train)\n",
    "  \n",
    "  preds = model.predict(X_test)\n",
    "  rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "  \n",
    "  return model, rmse\n",
    "\n",
    "def find_best_combination(model_type, combinations, train, test):\n",
    "  rmses = []\n",
    "  for feature_comb in combinations:\n",
    "      _, rmse = train_and_evaluate(model_type, train[feature_comb], train['oss'], test[feature_comb], test['oss'])\n",
    "      rmses.append(rmse)\n",
    "\n",
    "  min_rmse_index = np.argmin(rmses)\n",
    "  best_comb = combinations[min_rmse_index]\n",
    "  best_rmse = rmses[min_rmse_index]\n",
    "  return best_comb, best_rmse\n",
    "\n",
    "def read_and_process(directory):\n",
    "  files = os.listdir(directory)\n",
    "  df_list = []\n",
    "  for file in files:\n",
    "      if file.endswith('.csv'):\n",
    "          df = pd.read_csv(os.path.join(directory, file))\n",
    "          df = df.drop(['timestamp'], axis=1)\n",
    "          df = df.dropna()\n",
    "          df_list.append(df)\n",
    "  df_combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "  return df_combined\n",
    "\n",
    "def with_RMSE():\n",
    "  data_dir = \"./dms_data/\"\n",
    "  # Define directory paths\n",
    "  train_data_path = data_dir + '/train'\n",
    "  test_data_path = data_dir + '/test'\n",
    "\n",
    "  # Read and process data\n",
    "  train = read_and_process(train_data_path)\n",
    "  test = read_and_process(test_data_path)\n",
    "\n",
    "  # Define features\n",
    "  features = ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration',\n",
    "              'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk',\n",
    "              'm_jerk_var_480', 'm_jerk_stddev_480']\n",
    "\n",
    "  # Generate all combinations of features\n",
    "  feature_combinations = []\n",
    "  for r in range(1, len(features) + 1):\n",
    "      for subset in itertools.combinations(features, r):\n",
    "          feature_combinations.append(list(subset))\n",
    "\n",
    "  # Define models\n",
    "  models = [\"lgbm\", \"nn\", \"linear_regression\", \"svr\", \"random_forest\"]\n",
    "\n",
    "  # Find the best combination for each model\n",
    "  for model in models:\n",
    "      print('model: ' + model)\n",
    "      best_comb, best_rmse = find_best_combination(model, feature_combinations, train, test)\n",
    "      print(f\"Best feature combination for {model}: {best_comb}\")\n",
    "      print(f\"Best RMSE for {model}: {best_rmse}\")\n",
    "with_RMSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ac7d17-8d0e-4750-acf4-40eb6efa9500",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 9)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 85\u001b[0m\n\u001b[1;32m     83\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[1;32m     84\u001b[0m train, scaler \u001b[39m=\u001b[39m read_and_process(train_data_path, features, scaler, fit_scaler\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 85\u001b[0m test, _ \u001b[39m=\u001b[39m read_and_process(test_data_path, features, scaler)\n\u001b[1;32m     89\u001b[0m \u001b[39m# Generate all combinations of features\u001b[39;00m\n\u001b[1;32m     90\u001b[0m feature_combinations \u001b[39m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[8], line 66\u001b[0m, in \u001b[0;36mread_and_process\u001b[0;34m(directory, features, scaler, fit_scaler)\u001b[0m\n\u001b[1;32m     64\u001b[0m       scaler\u001b[39m.\u001b[39mfit(df[features])\n\u001b[1;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m scaler \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 66\u001b[0m       df[features] \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mtransform(df[features])\n\u001b[1;32m     67\u001b[0m     df_list\u001b[39m.\u001b[39mappend(df)\n\u001b[1;32m     68\u001b[0m df_combined \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(df_list, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/jupyter-env/lib64/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/jupyter-env/lib64/python3.9/site-packages/sklearn/preprocessing/_data.py:992\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m    989\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m    991\u001b[0m copy \u001b[39m=\u001b[39m copy \u001b[39mif\u001b[39;00m copy \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy\n\u001b[0;32m--> 992\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    993\u001b[0m     X,\n\u001b[1;32m    994\u001b[0m     reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    995\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    996\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    997\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    998\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    999\u001b[0m )\n\u001b[1;32m   1001\u001b[0m \u001b[39mif\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(X):\n\u001b[1;32m   1002\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_mean:\n",
      "File \u001b[0;32m~/jupyter-env/lib64/python3.9/site-packages/sklearn/base.py:565\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    564\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 565\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[1;32m    567\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/jupyter-env/lib64/python3.9/site-packages/sklearn/utils/validation.py:931\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    929\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[1;32m    930\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 931\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    932\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    933\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    934\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    935\u001b[0m         )\n\u001b[1;32m    937\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    938\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 9)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "data_dir = './dms_data/'\n",
    "\n",
    "\n",
    "def train_and_evaluate(model_type, X_train, y_train, X_test, y_test):\n",
    "  if model_type == \"lgbm\":\n",
    "    train_data = lgb.Dataset(X_train, label=y_train)\n",
    "    model = lgb.train({'verbose': -1}, train_data)\n",
    "  elif model_type == \"nn\":\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer=Adam())\n",
    "    model.fit(X_train, y_train, epochs=10, verbose=0)\n",
    "  elif model_type == \"linear_regression\":\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "  elif model_type == \"svr\":\n",
    "    model = SVR().fit(X_train, y_train)\n",
    "  elif model_type == \"random_forest\":\n",
    "    model = RandomForestRegressor().fit(X_train, y_train)\n",
    "\n",
    "  preds = model.predict(X_test)\n",
    "  rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "\n",
    "  return model, rmse\n",
    "\n",
    "\n",
    "def find_best_combination(model_type, combinations, train, test):\n",
    "  rmses = []\n",
    "  for feature_comb in combinations:\n",
    "    _, rmse = train_and_evaluate(model_type, train[feature_comb], train['oss'], test[feature_comb], test['oss'])\n",
    "    rmses.append(rmse)\n",
    "\n",
    "  min_rmse_index = np.argmin(rmses)\n",
    "  best_comb = combinations[min_rmse_index]\n",
    "  best_rmse = rmses[min_rmse_index]\n",
    "  return best_comb, best_rmse\n",
    "\n",
    "\n",
    "def read_and_process(directory, features, scaler=None, fit_scaler=False):\n",
    "  files = os.listdir(directory)\n",
    "  df_list = []\n",
    "  for file in files:\n",
    "    if file.endswith('.csv'):\n",
    "      df = pd.read_csv(os.path.join(directory, file))\n",
    "      df = df.drop(['timestamp'], axis=1)\n",
    "      df = df.dropna()\n",
    "\n",
    "      if fit_scaler:\n",
    "        scaler.fit(df[features])\n",
    "      if scaler is not None:\n",
    "        df[features] = scaler.transform(df[features])\n",
    "      df_list.append(df)\n",
    "  df_combined = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "  return df_combined, scaler\n",
    "\n",
    "\n",
    "# Define features\n",
    "features = ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration',\n",
    "            'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk',\n",
    "            'm_jerk_var_480', 'm_jerk_stddev_480']\n",
    "\n",
    "# Define directory paths\n",
    "train_data_path = data_dir + '/train'\n",
    "test_data_path = data_dir + '/test'\n",
    "\n",
    "# Read and process data\n",
    "scaler = StandardScaler()\n",
    "train, scaler = read_and_process(train_data_path, features, scaler, fit_scaler=True)\n",
    "test, _ = read_and_process(test_data_path, features, scaler)\n",
    "\n",
    "\n",
    "\n",
    "# Generate all combinations of features\n",
    "feature_combinations = []\n",
    "for r in range(1, len(features) + 1):\n",
    "  for subset in itertools.combinations(features, r):\n",
    "    feature_combinations.append(list(subset))\n",
    "\n",
    "# Define models\n",
    "models = [\"lgbm\", \"nn\", \"linear_regression\", \"svr\", \"random_forest\"]\n",
    "\n",
    "# Find the best combination for each model\n",
    "for model in models:\n",
    "  print('model: ' + model)\n",
    "  best_comb, best_rmse = find_best_combination(model, feature_combinations, train, test)\n",
    "  print(f\"Best feature combination for {model}: {best_comb}\")\n",
    "  print(f\"Best RMSE for {model}: {best_rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
