{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 20:09:43.202899: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-18 20:09:43.245371: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-18 20:09:43.245872: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-18 20:09:43.895743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "from sktime.forecasting.arima import AutoARIMA\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "from sktime.forecasting.fbprophet import Prophet\n",
    "\n",
    "DATA_DIR = './dms_data'\n",
    "N_TRIALS = 50\n",
    "\n",
    "features = ['m_speed', 'm_speed_var_480', 'm_speed_stddev_480', 'm_acceleration',\n",
    "            'm_acceleration_var_480', 'm_acceleration_stddev_480', 'm_jerk',\n",
    "            'm_jerk_var_480', 'm_jerk_stddev_480']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(file_path):\n",
    "  df = pd.read_csv(file_path)\n",
    "  return df.drop(['timestamp'], axis=1).dropna()\n",
    "\n",
    "\n",
    "def get_data_from_directory(directory_path):\n",
    "  files = [f for f in os.listdir(directory_path) if f.endswith('.csv')]\n",
    "  dfs = [load_and_preprocess_data(os.path.join(directory_path, f)) for f in files]\n",
    "  return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "\n",
    "train_data = get_data_from_directory(os.path.join(DATA_DIR, 'train'))\n",
    "test_data = get_data_from_directory(os.path.join(DATA_DIR, 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "  predictions = model.predict(X)\n",
    "  return np.sqrt(mean_squared_error(y, predictions))\n",
    "\n",
    "def print_results(rmse_results, title):\n",
    "  stats = {'平均値': np.mean, '中央値': np.median, '分散': np.var,\n",
    "           '標準偏差': np.std, '最小値': np.min, '最大値': np.max}\n",
    "  for stat, func in stats.items():\n",
    "    print(f\"[{title}] RMSEの{stat}: {func(rmse_results)}\")\n",
    "\n",
    "def get_data_lengths(data_dir, datasets=['test', 'train']):\n",
    "  data_lengths = []\n",
    "  for dataset in datasets:\n",
    "    path = os.path.join(data_dir, dataset)\n",
    "    for file in os.listdir(path):\n",
    "      if file.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(path, file))\n",
    "        data_lengths.append((dataset, file, len(df)))\n",
    "  return data_lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Importing plotly failed. Interactive plots will not work.\n"
     ]
    }
   ],
   "source": [
    "data_lengths = get_data_lengths(DATA_DIR)\n",
    "min_length_data = min(data_lengths, key=lambda x: x[2])\n",
    "\n",
    "excluded_subj = '20201127_1432_7'\n",
    "filtered_data_lengths = [d for d in data_lengths if excluded_subj not in d[1]]\n",
    "regressor = RandomForestRegressor()\n",
    "rf = make_reduction(regressor, strategy=\"recursive\", window_length=12, scitype=\"infer\")\n",
    "arima = AutoARIMA(sp=12, suppress_warnings=True)\n",
    "prophet = Prophet()\n",
    "\n",
    "models = {\"RandomForest\": rf, \"ARIMA\": arima, \"Prophet\": prophet}\n",
    "# models = {\"RandomForest\": rf, \"Prophet\": prophet}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 42\u001b[0m\n\u001b[1;32m     39\u001b[0m       data[(dataset_type, file)] \u001b[38;5;241m=\u001b[39m df\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# モデルのトレーニングと評価\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m results, predictions, actual_values \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(models, data, split_ratio)\u001b[0m\n\u001b[1;32m      8\u001b[0m split_point \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df) \u001b[38;5;241m*\u001b[39m split_ratio)\n\u001b[1;32m      9\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[:split_point], df\u001b[38;5;241m.\u001b[39miloc[split_point:]\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_train\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m y_test\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m     11\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     13\u001b[0m fh \u001b[38;5;241m=\u001b[39m ForecastingHorizon(y_test\u001b[38;5;241m.\u001b[39mindex, is_relative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/jupyter-env/lib64/python3.9/site-packages/pandas/core/generic.py:1466\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1465\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__nonzero__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NoReturn:\n\u001b[0;32m-> 1466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1467\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe truth value of a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is ambiguous. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1468\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1469\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "\n",
    "def train_and_evaluate(models, data, split_ratio=0.8):\n",
    "  results, predictions, actual_values = {}, {}, {}\n",
    "  for model_name, model in models.items():\n",
    "    all_errors, all_preds, all_actual = [], [], []\n",
    "    for (dataset_type, csv_file), df in data.items():\n",
    "      split_point = int(len(df) * split_ratio)\n",
    "      y_train, y_test = df.iloc[:split_point], df.iloc[split_point:]\n",
    "      if y_train.isna().any() or y_test.isna().any():\n",
    "        continue\n",
    "\n",
    "      fh = ForecastingHorizon(y_test.index, is_relative=False)\n",
    "      model.fit(y_train)\n",
    "      y_pred = model.predict(fh=fh)\n",
    "\n",
    "      if np.isnan(y_pred).any():\n",
    "        continue\n",
    "      all_preds.extend(y_pred)\n",
    "      all_actual.extend(y_test)\n",
    "      all_errors.append(mean_squared_error(y_test, y_pred))\n",
    "    results[model_name] = np.mean(all_errors)\n",
    "    predictions[model_name] = all_preds\n",
    "    actual_values[model_name] = all_actual\n",
    "  return results, predictions, actual_values\n",
    "\n",
    "\n",
    "\n",
    "data = {}\n",
    "for dataset_type in ['test', 'train']:\n",
    "  path = os.path.join(DATA_DIR, dataset_type)\n",
    "  for file in os.listdir(path):\n",
    "    if file.endswith(\".csv\") and excluded_subj not in file:\n",
    "      df = pd.read_csv(os.path.join(path, file))\n",
    "      df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "      df.set_index('timestamp', inplace=True)\n",
    "      df = df.asfreq('20MS')\n",
    "      df = df.dropna()\n",
    "      data[(dataset_type, file)] = df\n",
    "\n",
    "# モデルのトレーニングと評価\n",
    "results, predictions, actual_values = train_and_evaluate(models, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
